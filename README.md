# Wide & Deep Recommendation Model

This project implements a Wide & Deep model using TensorFlow/Keras, designed for basic structured data recommendation tasks.  
It includes data generation, feature engineering, model building, training, evaluation, and model saving.

---

## ðŸ“Œ Project Structure

```
wide_deep_rec/
â”œâ”€â”€ configs/                     # Base configuration files
â”‚   â””â”€â”€ config.yaml              # Default configuration
â”œâ”€â”€ experiment_configs/          # Experiment-specific configurations
â”‚   â”œâ”€â”€ baseline.yaml            # Default settings
â”‚   â”œâ”€â”€ deep_network.yaml        # Deeper neural network
â”‚   â”œâ”€â”€ high_dropout.yaml        # Higher regularization
â”‚   â””â”€â”€ ...                      # Other experiment configs
â”œâ”€â”€ scripts/                     # Core implementation
â”‚   â”œâ”€â”€ model.py                 # Wide & Deep model definition
â”‚   â”œâ”€â”€ train.py                 # Training pipeline
â”‚   â”œâ”€â”€ data_processor.py        # Data processing utilities
â”‚   â””â”€â”€ preprocess_original.py   # Original data preprocessing script
â”œâ”€â”€ data/                        # Data directory
â”‚   â”œâ”€â”€ train.csv                # Training data
â”‚   â”œâ”€â”€ valid.csv                # Validation data 
â”‚   â””â”€â”€ test.csv                 # Test data
â”œâ”€â”€ experiments/                 # Experiment outputs (auto-generated)
â”‚   â”œâ”€â”€ baseline/                # Results for baseline experiment
â”‚   â”œâ”€â”€ deep_network/            # Results for deep network experiment
â”‚   â””â”€â”€ ...                      # Other experiment results
â”œâ”€â”€ run_experiments.py           # Main experiment runner
â”œâ”€â”€ run.py                       # Single execution runner
```

---

## ðŸš€ Quick Start

### 1. Install Requirements

You should have Python 3.8+ installed.  
Recommended to use a virtual environment.

```bash
pip install -r requirements.txt
```

(*If `requirements.txt` not available, the key libraries are: `tensorflow`, `pandas`, `numpy`, `pyyaml`.*)

---

### 2. Generate Dataset

Synthetic datasets are automatically generated using:

```bash
python3 run.py --preprocess
```
(*By default, it preprocess the movie_raw_data and make them into the train/test/valid.csv files to be ready for train*)

---

### 3. Configure Training Parameters

Edit `configs/config.yaml` to adjust:

- Dataset paths
- Label column
- Batch size, number of epochs
- Model hidden layers and dropout rate

Example (`configs/config.yaml`):

```yaml
data:
  train_data_path: data/train.csv
  valid_data_path: data/valid.csv
  test_data_path: data/test.csv
  label_column: label

train:
  batch_size: 256
  epochs: 10

eval:
  batch_size: 512

model:
  hidden_units: [128, 64, 32]
  dropout_rate: 0.5
```
for experiment configs, please visit experiment_configs/
and change the files inside
---

### 4. Train and Evaluate

Simply run:

```bash
python3 -m scripts.train
```

- The model will train, validate, and evaluate on the test set.
- Metrics such as AUC, Precision, Recall, and Loss will be printed.
- The trained model will be saved in `saved_model/`.

---
Running Experiments:
Option 1: Run a single experiment
```bash
python run_experiments.py --experiment baseline
```
Available experiments include:
baseline
deep_network
high_dropout
small_batch
large_batch
no_dropout
sgd_optimizer
wide_only
deep_only
comedy_only
high_learning_rate
low_learning_rate
no_early_stopping
large_embeddings
minimal_epochs
---
Option 2: Run all experiments
```bash
python run_experiments.py --run-all
```
---
Option 3: Compare results
```bash
python run_experiments.py --compare
```

## ðŸ“ˆ Model Test Performance Example

| Metric | Value |
|:------|:------|
| Test Loss | ~0.079 |
| Test AUC | ~0.800 |
| Test Precision | ~0.983 |
| Test Recall | ~1.000 |

---

## Experiment Performance:

## Experiment Results

Our comprehensive experiments revealed significant performance variations across model configurations:

| Experiment          | AUC      | Precision | Recall   | Loss     |
|---------------------|:--------:|:---------:|:--------:|:--------:|
| small_batch         | **0.804**| 0.914     | 0.977    | **0.277**|
| high_learning_rate  | 0.801    | 0.901     | 0.995    | 0.278    |
| no_dropout          | 0.800    | 0.908     | 0.986    | 0.278    |
| deep_network        | 0.797    | 0.903     | 0.992    | 0.282    |
| baseline            | 0.797    | 0.897     | 0.997    | 0.283    |
| large_batch         | 0.790    | 0.905     | 0.989    | 0.285    |
| high_dropout        | 0.788    | 0.897     | 0.997    | 0.294    |
| low_learning_rate   | 0.752    | 0.893     | 1.000    | 0.302    |
| no_early_stopping   | 0.658    | 0.868     | 1.000    | 0.374    |
| large_embeddings    | 0.611    | 0.893     | 1.000    | 0.334    |
| sgd_optimizer       | 0.605    | 0.893     | 1.000    | 0.335    |
| deep_only           | 0.602    | 0.893     | 1.000    | 0.335    |
| minimal_epochs      | 0.602    | 0.893     | 1.000    | 0.335    |
| comedy_only         | 0.599    | 0.868     | 1.000    | 0.386    |
| wide_only           | 0.568    | 0.893     | 1.000    | 0.341    |

*Best values for each metric are in bold*

## ðŸ’¬ Contact

If you have any questions or suggestions, feel free to reach out:

- **Author:** Ruoran Jia

---

## ðŸ“œ License

This project is licensed under the MIT License.  
Feel free to use, modify, and distribute with attribution.
